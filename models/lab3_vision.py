# -*- coding: utf-8 -*-
"""Lab3 - Vision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J0-CFf3H-ZbR0axClNIKOjwnA8dOuZ0x
"""

#Import Dataset Cats & Dogs
import torch
import os
import kagglehub
from torchvision import datasets,models, transforms
from torch.utils.data import DataLoader, random_split
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
from torchsummary import summary
import torch

# --- Variabili di Base ---
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
input_size = 224
num_workers = 2 #

dataset_path = kagglehub.dataset_download("tongpython/cat-and-dog")
print("Path to dataset files:", dataset_path)
print('Data source import complete.')

class SimpleEarlyStopping:
    """Versione semplice: si ferma appena la validation loss smette di migliorare."""
    def __init__(self, patience=3):
        self.patience = patience
        self.best_loss = None
        self.counter = 0
        self.should_stop = False

    def step(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
            print(f"ðŸ“Š Best val loss: {val_loss:.4f}")
        elif val_loss < self.best_loss:
            self.best_loss = val_loss
            self.counter = 0
            print(f"âœ“ Migliorato! New best: {val_loss:.4f}")
        else:
            self.counter += 1
            print(f"âš ï¸ Nessun miglioramento ({self.counter}/{self.patience})")
            if self.counter >= self.patience:
                self.should_stop = True
                print(f"ðŸ›‘ STOP! Nessun miglioramento per {self.patience} epoche")

print("âœ“ Classe SimpleEarlyStopping pronta!")

#Set directories
#dataset_path = '/kaggle/input/cat-and-dog'
train_path = os.path.join(dataset_path, 'training_set', 'training_set')
test_path = os.path.join(dataset_path, 'test_set', 'test_set')

# Funzione per creare il file CSV delle annotazioni
def create_annotations_csv(data_dir, output_csv):
    data = []

    # Cerca immagini di cani
    dogs_dir = os.path.join(data_dir, 'dogs')
    if os.path.exists(dogs_dir):
        for img_name in os.listdir(dogs_dir):
            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                data.append({
                    'filename': os.path.join('dogs', img_name),
                    'label': 1  # 1 per cani
                })

    # Cerca immagini di gatti
    cats_dir = os.path.join(data_dir, 'cats')
    if os.path.exists(cats_dir):
        for img_name in os.listdir(cats_dir):
            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                data.append({
                    'filename': os.path.join('cats', img_name),
                    'label': 0  # 0 per gatti
                })

    # Crea DataFrame e salva come CSV
    df = pd.DataFrame(data)
    df.to_csv(output_csv, index=False)
    print(f"Creato {output_csv} con {len(df)} immagini")
    print(f"Gatti: {len(df[df['label'] == 0])}, Cani: {len(df[df['label'] == 1])}")
    return df

# Crea i file CSV per training e test
train_annotations = create_annotations_csv(train_path, 'train_annotations.csv')
test_annotations = create_annotations_csv(test_path, 'test_annotations.csv')

import os
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from torchvision.io import read_image
from PIL import Image
import torch
from torchvision import transforms

class CustomImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        """
        Args:
            annotations_file: Percorso del file CSV con le annotazioni
            img_dir: Directory contenente le immagini
            transform: Trasformazioni da applicare alle immagini
            target_transform: Trasformazioni da applicare alle label
        """
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        # Ottieni il percorso dell'immagine
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])

        # Leggi l'immagine usando PIL (piÃ¹ compatibile)
        image = Image.open(img_path).convert('RGB')

        # Ottieni la label
        label = self.img_labels.iloc[idx, 1]

        # Applica le trasformazioni
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)

        return image, label

# Definisci le trasformazioni per le immagini
transform = transforms.Compose([
    #transforms.Resize((224, 224)),  # Ridimensiona a 224x224
    transforms.Resize(input_size),  # Ridimensiona casualmente a 224x224
    transforms.CenterCrop(input_size),
    #transforms.RandomHorizontalFlip(),  # Flip orizzontale casuale p=0.5
    transforms.RandomRotation(degrees=5),
    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),
    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),  # Converti in tensor
    transforms.Normalize(mean=mean,std=std)
])

# Trasformazioni per il test set (senza augmentation)
test_transform = transforms.Compose([
    #transforms.Resize((224, 224)),
    transforms.Resize(input_size),  # Ridimensiona casualmente a 224x224
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean,std=std)
])

# Crea i dataset
train_dataset = CustomImageDataset(
    annotations_file='train_annotations.csv',
    img_dir=train_path,
    transform=transform
)

test_dataset = CustomImageDataset(
    annotations_file='test_annotations.csv',
    img_dir=test_path,
    transform=test_transform
)

# Split train_dataset into train and validation (80/20 split)
train_size = int(0.85 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_subset, val_subset = random_split(train_dataset, [train_size, val_size])

# Crea i DataLoader
batch_size = 128

train_loader = DataLoader(
    train_subset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=num_workers
)

val_loader = DataLoader(
    val_subset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers
)

test_loader = DataLoader(
    test_dataset,
    batch_size=batch_size,
    shuffle=False,
    num_workers=num_workers
)

# Create dataloaders dictionary
dataloaders = {
    'train': train_loader,
    'val': val_loader,
    'test': test_loader
}

print("âœ“ DataLoaders dictionary created")
print(f"  - Train samples: {len(train_subset)}")
print(f"  - Validation samples: {len(val_subset)}")
print(f"  - Test samples: {len(test_dataset)}")
print(f"  - Batch size: {batch_size}")
print(f"  - Train batches: {len(train_loader)}")
print(f"  - Validation batches: {len(val_loader)}")
print(f"  - Test batches: {len(test_loader)}")

import matplotlib.pyplot as plt
import numpy as np

# Funzione per denormalizzare le immagini
def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    for t, m, s in zip(tensor, mean, std):
        t.mul_(s).add_(m)
    return tensor

# Ottieni un batch di immagini
images, labels = next(iter(train_loader))

# Visualizza le prime 8 immagini
fig, axes = plt.subplots(2, 4, figsize=(12, 6))
axes = axes.ravel()

for idx in range(8):
    # Denormalizza l'immagine
    img = images[idx].clone()
    img = denormalize(img)
    img = img.permute(1, 2, 0).numpy()
    img = np.clip(img, 0, 1)

    # Visualizza
    axes[idx].imshow(img)
    axes[idx].set_title(f"{'Gatto' if labels[idx] == 0 else 'Cane'}")
    axes[idx].axis('off')

plt.tight_layout()
plt.show()

model_ft = models.vgg16(weights='IMAGENET1K_V1') # modello preallenato che sfruttiamo
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_ft = model_ft.to(device)

summary(model_ft, (3, 224, 224), device='cuda' if torch.cuda.is_available() else 'cpu')

num_classes = 2 # task cat vs dog
num_ftrs = model_ft.classifier[6].in_features # sostituisco ultimo layer con nuovo
model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes) # cambio il numero finale di classi da predirre, numero task mio

# Ensure the model is on the correct device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_ft = model_ft.to(device)

# Use summary and specify the device
# torchsummary expects 'cuda' or 'cpu', not 'cuda:0'
summary(model_ft, (3, 224, 224), device='cuda' if torch.cuda.is_available() else 'cpu')

# Freeze all layers first
for param in model_ft.parameters():
  param.requires_grad = False

# Unfreeze the parameters of the last layer of the classifier
#for param in model_ft.classifier[6].parameters():
#  param.requires_grad = True

#import torch.nn as nn
#from torchvision import models

# --- Assumiamo che model_ft sia stato caricato e congelato ---
# model_ft = models.vgg16(weights='IMAGENET1K_V1')
# for param in model_ft.parameters():
#     param.requires_grad = False
# -----------------------------------------------------------

# 1. Sblocco gli strati convoluzionali di alto livello
# VGG16 features (modulo nn.Sequential) ha 31 sottomoduli (da 0 a 30).
# L'ultimo blocco di convoluzione inizia tipicamente intorno all'indice 24.

# Indice di partenza per lo sblocco:
# Se vogliamo sbloccare solo gli strati piÃ¹ profondi (es. gli ultimi 3 Conv2d e le loro ReLU/MaxPool),
# possiamo iniziare l'unfreezing dal 4Â° blocco o 5Â° blocco (dalla fine).
# Per sbloccare l'ULTIMO BLOCCO LOGICO di convoluzione (che prepara le feature finali):
unfreeze_start_index = 24

# Itera attraverso il modulo features (strati convoluzionali)
for name, child in model_ft.features.named_children():
    # 'name' Ã¨ l'indice dello strato (0, 1, 2, ..., 30)
    if int(name) >= unfreeze_start_index:
        for param in child.parameters():
            param.requires_grad = True

# 2. Sblocco l'intero classificatore (head)
for param in model_ft.classifier.parameters():
    param.requires_grad = True

# 3. Aggiornamento dell'Ottimizzatore
# (Cruciale: la LR deve essere MOLTO piÃ¹ bassa per le features convoluzionali)

# Esempio di come l'ottimizzatore dovrebbe essere aggiornato:
# optimizer = optim.SGD([
#     {'params': model_ft.classifier.parameters(), 'lr': 1e-3},         # LR piÃ¹ alta per il classificatore
#     {'params': (param for param in model_ft.features.parameters() if param.requires_grad), 'lr': 1e-5} # LR molto piÃ¹ bassa per le features sbloccate
# ], momentum=0.9)

summary(model_ft, (3, 224, 224))

"""Calcolo dei Parametri AddestrabiliL'ultimo strato lineare esegue l'operazione: $y = Wx + b$.Pesi ($W$): $4096$ (input) $\times 2$ (output classi) $= 8192$ parametriBias ($b$): $2$ parametri (uno per classe)Totale Parametri Addestrabili: $8192 + 2 = \mathbf{8194}$"""

import torch.optim as optim


# Device configuration
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Move model to device
model_ft = model_ft.to(device)

# Loss function
criterion = nn.CrossEntropyLoss()

# Optimizer - only parameters with requires_grad=True
#optimizer_ft = optim.Adam(
#    filter(lambda p: p.requires_grad, model_ft.parameters()),
#    lr=0.00001
#)

# Learning rate scheduler
#scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# Sostituisci l'Optimizer Adam con SGD
optimizer_ft = optim.SGD(
    filter(lambda p: p.requires_grad, model_ft.parameters()),
    weight_decay=1e-5,
    lr=0.0001,  # Aumenta la LR rispetto ad Adam (Adam ha una LR piÃ¹ piccola)
    momentum=0.9 # Momentum Ã¨ essenziale per SGD
)

# Learning rate scheduler (meno aggressivo)
scheduler = optim.lr_scheduler.StepLR(
    optimizer_ft,
    step_size=5,
    gamma=0.5
)

print("âœ“ Training setup complete")
print(f"  - Loss: CrossEntropyLoss")
print(f"  - Optimizer: SDG (lr=0.0001)")
print(f"  - Scheduler: StepLR (step_size=7, gamma=0.5)")

def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=10):
    """
    Train the model and return training history

    Args:
        model: PyTorch model
        criterion: Loss function
        optimizer: Optimizer
        scheduler: Learning rate scheduler
        dataloaders: Dictionary with 'train' and 'val' dataloaders
        num_epochs: Number of training epochs

    Returns:
        model: Trained model
        history: Dictionary with training history
    """
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # Dictionary to store loss and accuracy
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    early_stop = SimpleEarlyStopping(patience=8)

    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch+1}/{num_epochs}')
        print('-' * 60)

        # Each epoch has training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
                dataloader = dataloaders['train']
            else:
                model.eval()   # Set model to evaluate mode
                dataloader = dataloaders['val']

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data
            pbar = tqdm(dataloader, desc=f'{phase.capitalize()} ')
            for inputs, labels in pbar:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # Zero the parameter gradients
                optimizer.zero_grad()

                # Forward pass
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # Backward + optimize only in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # Statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

                # Update progress bar
                pbar.set_postfix({'loss': f'{loss.item():.4f}'})

            if phase == 'train':
                scheduler.step()

            # Calculate epoch statistics
            epoch_loss = running_loss / len(dataloader.dataset)
            epoch_acc = running_corrects.double() / len(dataloader.dataset)

            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # Save to history
            if phase == 'train':
                history['train_loss'].append(epoch_loss)
                history['train_acc'].append(epoch_acc.item())
            else:
                history['val_loss'].append(epoch_loss)
                history['val_acc'].append(epoch_acc.item())

                # Early stopping - Pass the current epoch_loss for validation
                early_stop.step(epoch_loss)
                if early_stop.should_stop:
                    print(f"Early stopping at epoch {epoch}")
                    # Break from both inner and outer loop
                    return model, history # Return early if early stopping is triggered


            # Deep copy the best model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
                print(f'âœ“ New best model! Validation Accuracy: {best_acc:.4f}')


    time_elapsed = time.time() - since
    print(f'\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best Validation Accuracy: {best_acc:.4f}')

    # Load best model weights
    model.load_state_dict(best_model_wts)
    return model, history

print("âœ“ Training function defined")

import time
import copy
from tqdm import tqdm


print("=" * 60)
print("PHASE 1: Feature Extraction (only last layer trainable)")
print("=" * 60)

num_epochs_feature_extraction = 15

model_ft_trained, history_ft = train_model(
    model_ft,
    criterion,
    optimizer_ft,
    scheduler,
    dataloaders,
    num_epochs=num_epochs_feature_extraction
)

def plot_training_history(history, title='Training History'):
    """Plot training and validation loss and accuracy"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Loss plot
    ax1.plot(history['train_loss'], label='Train Loss', marker='o')
    ax1.plot(history['val_loss'], label='Validation Loss', marker='s')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title(f'{title} - Loss')
    ax1.legend()
    ax1.grid(True)

    # Accuracy plot
    ax2.plot(history['train_acc'], label='Train Accuracy', marker='o')
    ax2.plot(history['val_acc'], label='Validation Accuracy', marker='s')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.set_title(f'{title} - Accuracy')
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    plt.show()

plot_training_history(history_ft, 'Feature Extraction (Frozen Base)')

import torch.nn.functional as F
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

def test_model(model, dataloader, device):
    """
    Test the model on test set

    Args:
        model: Trained PyTorch model
        dataloader: Test DataLoader
        device: Device to run evaluation on
    """
    model.eval()
    test_loss = 0
    correct = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for data, target in tqdm(dataloader, desc='Testing'):
            batch_size_current = data.shape[0]
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, reduction='sum').item()

            pred = output.argmax(dim=1, keepdim=True)

            # Sanity check
            pred = pred.view(batch_size_current)
            target = target.view(batch_size_current)

            # Compute prediction ok
            batch_pred_ok = pred.eq(target).sum().item()
            correct += batch_pred_ok

            # Store predictions and labels
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(target.cpu().numpy())

    test_loss /= len(dataloader.dataset)
    num_samples = len(dataloader.dataset)
    test_accuracy = correct / num_samples

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\n'.format(
        test_loss, correct, len(dataloader.dataset),
        100. * test_accuracy))

    return test_accuracy, all_preds, all_labels

print("âœ“ Test function defined")

def detailed_evaluation(all_labels, all_preds):
    """
    Show detailed evaluation metrics

    Args:
        all_labels: True labels
        all_preds: Predicted labels
    """
    # Classification report
    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds,
                                target_names=['Cats', 'Dogs']))

    # Confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Cats', 'Dogs'],
                yticklabels=['Cats', 'Dogs'])
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

print("âœ“ Detailed evaluation function defined")

print("=" * 60)
print("FINAL EVALUATION ON TEST SET - Feature Extraction")
print("=" * 60)

# Test on the test set
test_accuracy, test_preds, test_labels = test_model(
    model_ft_trained,
    dataloaders['test'],
    device
)

# Show detailed metrics
detailed_evaluation(test_labels, test_preds)

print(f"\n{'='*60}")
print(f"FINAL RESULTS:")
print(f"  - Best Validation Accuracy: {max(history_ft['val_acc']):.4f}")
print(f"  - Final Test Accuracy: {test_accuracy:.4f}")
print(f"{'='*60}")